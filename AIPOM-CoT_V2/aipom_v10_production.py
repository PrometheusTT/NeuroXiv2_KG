"""
AIPOM-CoT V10 PRODUCTION
========================
å®Œæ•´é›†æˆæ‰€æœ‰P0å’ŒP1ç»„ä»¶:
âœ… P0-1: æ™ºèƒ½å®ä½“è¯†åˆ« (IntelligentEntityRecognizer)
âœ… P0-2: Benchmarkè¯„ä¼°ç³»ç»Ÿ (BenchmarkRunner)
âœ… P1-1: åŠ¨æ€Schemaè·¯å¾„è§„åˆ’ (DynamicSchemaPathPlanner)
âœ… P1-2: ç»“æ„åŒ–åæ€ (StructuredReflector)

è¿™æ˜¯ç”Ÿäº§å°±ç»ªç‰ˆæœ¬,å¯ä»¥ç›´æ¥ç”¨äº:
- å®Œæ•´Benchmarkè¯„ä¼°
- è®ºæ–‡Figure 3/4/5å¤ç°
- ä¸baselineå¯¹æ¯”

Author: Claude & PrometheusTT
Date: 2025-01-12
"""

import json
import logging
import os
import time
from typing import Any, Dict, List, Optional
from dataclasses import dataclass, field
import re
from pathlib import Path

import numpy as np

from neo4j_exec import Neo4jExec
from adaptive_planner import AdaptivePlanner, AnalysisDepth, AnalysisState
from aipom_cot_true_agent_v2 import (
    RealSchemaCache,
    StatisticalTools,
    RealFingerprintAnalyzer,
    AgentPhase,
    AgentState,
    ReasoningStep
)

# å¯¼å…¥æ–°ç»„ä»¶
from intelligent_entity_recognition import (
    IntelligentEntityRecognizer,
    EntityClusteringEngine
)
from schema_path_planner import DynamicSchemaPathPlanner
from structured_reflection import StructuredReflector

try:
    from openai import OpenAI
except ImportError:
    raise ImportError("Please install openai: pip install openai")

logger = logging.getLogger(__name__)


# ==================== Enhanced Agent State ====================

@dataclass
class EnhancedAgentState(AgentState):
    """æ‰©å±•çš„AgentçŠ¶æ€"""

    # æ–°å¢å­—æ®µ
    entity_matches: List = field(default_factory=list)  # EntityMatchåˆ—è¡¨
    entity_clusters: List = field(default_factory=list)  # EntityClusteråˆ—è¡¨
    structured_reflections: List = field(default_factory=list)  # StructuredReflectionåˆ—è¡¨
    schema_paths_used: List = field(default_factory=list)  # ä½¿ç”¨çš„schemaè·¯å¾„


# ==================== Production Agent V10 ====================

class AIPOMCoTV10:
    """
    AIPOM-CoT V10 ç”Ÿäº§ç‰ˆæœ¬

    å®Œæ•´åŠŸèƒ½:
    1. æ™ºèƒ½å®ä½“è¯†åˆ« (æ— éœ€hardcodedåˆ—è¡¨)
    2. åŠ¨æ€Schemaè·¯å¾„è§„åˆ’ (å›¾ç®—æ³•)
    3. ç»“æ„åŒ–åæ€ (é‡åŒ–è¯„ä¼°)
    4. å®Œæ•´ç»Ÿè®¡å·¥å…·
    5. å¤šæ¨¡æ€åˆ†æ
    6. è‡ªé€‚åº”é‡è§„åˆ’
    """

    def __init__(self,
                 neo4j_uri: str,
                 neo4j_user: str,
                 neo4j_pwd: str,
                 database: str,
                 schema_json_path: str,
                 openai_api_key: Optional[str] = None,
                 model: str = "gpt-4o"):

        # æ•°æ®åº“è¿æ¥
        self.db = Neo4jExec(neo4j_uri, neo4j_user, neo4j_pwd, database=database)

        # Schema
        self.schema = RealSchemaCache(schema_json_path)

        # ===== æ ¸å¿ƒç»„ä»¶åˆå§‹åŒ– =====

        # P0-1: æ™ºèƒ½å®ä½“è¯†åˆ«
        logger.info("ğŸ” Initializing intelligent entity recognition...")
        self.entity_recognizer = IntelligentEntityRecognizer(self.db, self.schema)
        self.entity_clusterer = EntityClusteringEngine(self.db, self.schema)

        # P1-1: åŠ¨æ€Schemaè·¯å¾„è§„åˆ’
        logger.info("ğŸ—ºï¸  Initializing dynamic schema path planning...")
        self.path_planner = DynamicSchemaPathPlanner(self.schema)

        # P1-2: ç»“æ„åŒ–åæ€
        logger.info("ğŸ¤” Initializing structured reflection...")
        self.reflector = StructuredReflector()

        # åŸæœ‰ç»„ä»¶
        self.stats = StatisticalTools()
        self.fingerprint = RealFingerprintAnalyzer(self.db, self.schema)

        # OpenAI
        self.client = OpenAI(api_key=openai_api_key)
        self.model = model


        self.adaptive_planner = AdaptivePlanner(self.schema, self.path_planner,self.client)

        logger.info("âœ… AIPOM-CoT V10 initialized successfully!")
        logger.info(f"   â€¢ Entity recognition: Ready")
        logger.info(f"   â€¢ Schema path planning: Ready")
        logger.info(f"   â€¢ Structured reflection: Ready")

    # ==================== Main Entry Point ====================

    """
    å®Œæ•´çš„answeræ–¹æ³•å®ç° - é›†æˆè‡ªé€‚åº”è§„åˆ’
    """

    def answer(self, question: str, max_iterations: int = 15) -> Dict[str, Any]:
        """
        ä¸»å…¥å£: å›ç­”é—®é¢˜ (ä½¿ç”¨è‡ªé€‚åº”è§„åˆ’)

        å®Œæ•´æµç¨‹:
        1. å®ä½“è¯†åˆ« + èšç±»
        2. ç¡®å®šåˆ†ææ·±åº¦
        3. åˆå§‹åŒ–åˆ†æçŠ¶æ€
        4. è‡ªé€‚åº”æ‰§è¡Œå¾ªç¯
        5. ç­”æ¡ˆåˆæˆ
        """
        logger.info(f"ğŸ¯ Question: {question}")
        start_time = time.time()

        state = EnhancedAgentState(question=question)

        # ===== PHASE 1: INTELLIGENT PLANNING =====
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ“‹ PHASE 1: INTELLIGENT PLANNING (Enhanced)")
        logger.info("=" * 70)

        state.phase = AgentPhase.PLANNING

        # Step 1-2: å®ä½“è¯†åˆ« + èšç±» (ä¸å˜)
        logger.info("  [1/4] Intelligent entity recognition...")
        entity_matches = self.entity_recognizer.recognize_entities(question)
        state.entity_matches = entity_matches

        logger.info(f"     Found {len(entity_matches)} entity matches")
        for match in entity_matches[:5]:
            logger.info(f"       â€¢ {match.text} ({match.entity_type}) [{match.confidence:.2f}]")

        logger.info("  [2/4] Entity clustering...")
        entity_clusters = self.entity_clusterer.cluster_entities(entity_matches, question)
        state.entity_clusters = entity_clusters

        logger.info(f"     Created {len(entity_clusters)} entity clusters")
        for cluster in entity_clusters:
            logger.info(f"       â€¢ {cluster.cluster_type}: {cluster.primary_entity.text}")

        # ğŸ†• Step 3: ç¡®å®šåˆ†ææ·±åº¦
        from adaptive_planner import determine_analysis_depth, AnalysisState, AnalysisDepth

        logger.info("  [3/4] Determining analysis depth...")
        target_depth = determine_analysis_depth(question)
        logger.info(f"     Depth: {target_depth.value}")

        # ğŸ†• Step 4: åˆå§‹åŒ–åˆ†æçŠ¶æ€
        logger.info("  [4/4] Initializing analysis state...")

        analysis_state = AnalysisState(
            discovered_entities={},
            executed_steps=[],
            modalities_covered=[],
            current_focus='gene' if entity_clusters and entity_clusters[0].cluster_type == 'gene_marker' else 'region',
            target_depth=target_depth,
            question_intent=self._classify_question_intent(question)
        )

        # å¡«å……åˆå§‹å®ä½“
        for cluster in entity_clusters:
            entity_type = cluster.primary_entity.entity_type
            entity_id = cluster.primary_entity.entity_id

            analysis_state.discovered_entities.setdefault(entity_type, []).append(entity_id)

            # æ·»åŠ related entities
            for related in cluster.related_entities:
                analysis_state.discovered_entities.setdefault(
                    related.entity_type, []
                ).append(related.entity_id)

        # å…¼å®¹æ€§: ä¿å­˜åˆ°state
        state.entities = [
            {'text': m.text, 'type': m.entity_type, 'confidence': m.confidence}
            for m in entity_matches[:10]
        ]

        logger.info(f"âœ… Planning complete")
        logger.info(f"   â€¢ Target depth: {target_depth.value}")
        logger.info(f"   â€¢ Initial entities: {list(analysis_state.discovered_entities.keys())}")

        # ===== PHASE 2: ADAPTIVE EXECUTION =====
        logger.info("\n" + "=" * 70)
        logger.info("âš™ï¸ PHASE 2: ADAPTIVE EXECUTION (Dynamic Planning)")
        logger.info("=" * 70)

        state.phase = AgentPhase.EXECUTING

        iteration = 0
        while iteration < max_iterations:
            # ğŸ†• å†³å®šæ˜¯å¦ç»§ç»­
            if not self.adaptive_planner.should_continue(analysis_state, question):
                logger.info("ğŸ“Œ Analysis complete (adaptive decision)")
                break

            # ğŸ†• åŠ¨æ€è§„åˆ’ä¸‹ä¸€æ­¥
            logger.info(f"\nğŸ¯ Adaptive planning (iteration {iteration + 1})...")
            next_steps = self.adaptive_planner.plan_next_steps(
                analysis_state,
                question,
                max_steps=2  # æ¯æ¬¡è§„åˆ’2æ­¥
            )

            if not next_steps:
                logger.info("ğŸ“Œ No more valuable steps available")
                break

            # æ‰§è¡Œè§„åˆ’çš„æ­¥éª¤
            for candidate_step in next_steps:
                if iteration >= max_iterations:
                    break

                logger.info(f"\nğŸ”¹ Step {iteration + 1}: {candidate_step.purpose}")
                logger.info(f"   Type: {candidate_step.step_type}")
                logger.info(f"   LLM score: {candidate_step.llm_score:.2f}")

                # ğŸ†• è½¬æ¢CandidateStepä¸ºReasoningStep
                reasoning_step = self._convert_candidate_to_reasoning(
                    candidate_step,
                    iteration + 1,
                    analysis_state
                )

                # æ‰§è¡Œ
                exec_result = self._execute_step(reasoning_step, state)

                if not exec_result['success']:
                    logger.error(f"   âŒ Failed: {exec_result.get('error')}")

                    # ç®€å•é‡è§„åˆ’ (å¦‚æœéœ€è¦)
                    if state.replanning_count < state.max_replanning:
                        logger.info(f"   ğŸ”„ Replanning...")
                        state.replanning_count += 1
                        # ç»§ç»­å¾ªç¯,è‡ªé€‚åº”è§„åˆ’ä¼šç”Ÿæˆæ–°æ­¥éª¤

                    continue

                # ğŸ†• ç»“æ„åŒ–åæ€
                structured_reflection = self.reflector.reflect(
                    step_number=reasoning_step.step_number,
                    purpose=reasoning_step.purpose,
                    expected_result=reasoning_step.expected_result,
                    actual_result=reasoning_step.actual_result,
                    question_context=question
                )

                reasoning_step.reflection = structured_reflection.summary
                reasoning_step.validation_passed = (
                        structured_reflection.validation_status.value in ['passed', 'partial']
                )

                state.structured_reflections.append(structured_reflection)
                state.reflections.append(structured_reflection.summary)

                logger.info(f"   ğŸ“Š Reflection: {structured_reflection.summary}")
                logger.info(f"   ğŸ“ˆ Confidence: {structured_reflection.confidence_score:.3f}")

                # ğŸ†• æ›´æ–°åˆ†æçŠ¶æ€
                self._update_analysis_state(
                    analysis_state,
                    reasoning_step,
                    exec_result,
                    candidate_step
                )

                state.executed_steps.append(reasoning_step)
                iteration += 1

        # ===== PHASE 3: ANSWER SYNTHESIS =====
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ“ PHASE 3: ANSWER SYNTHESIS")
        logger.info("=" * 70)

        final_answer = self._synthesize_answer(state)

        execution_time = time.time() - start_time

        # æ„å»ºè¿”å›ç»“æœ
        result = {
            'question': question,
            'answer': final_answer,

            # å®ä½“è¯†åˆ«
            'entities_recognized': [
                {
                    'text': m.text,
                    'type': m.entity_type,
                    'confidence': m.confidence,
                    'match_type': m.match_type
                }
                for m in state.entity_matches[:10]
            ],

            # æ¨ç†è®¡åˆ’
            'reasoning_plan': [self._step_to_dict(s) for s in state.executed_steps],
            'executed_steps': [self._step_to_dict(s) for s in state.executed_steps],

            # åæ€
            'reflections': state.reflections,
            'structured_reflections': [
                {
                    'step': r.step_number,
                    'status': r.validation_status.value,
                    'confidence': r.confidence_score,
                    'uncertainty': r.uncertainty.overall_uncertainty,
                    'should_replan': r.should_replan
                }
                for r in state.structured_reflections
            ],

            # ğŸ†• è‡ªé€‚åº”è§„åˆ’ä¿¡æ¯
            'adaptive_planning': {
                'target_depth': target_depth.value,
                'final_depth': len(state.executed_steps),
                'modalities_covered': analysis_state.modalities_covered,
                'entities_discovered': {
                    k: len(v) for k, v in analysis_state.discovered_entities.items()
                }
            },

            # å…ƒæ•°æ®
            'replanning_count': state.replanning_count,
            'confidence_score': state.confidence_score,
            'execution_time': execution_time,
            'total_steps': len(state.executed_steps),
            'schema_paths_used': state.schema_paths_used
        }

        logger.info(f"\nâœ… Completed in {execution_time:.2f}s")
        logger.info(f"   â€¢ Steps executed: {len(state.executed_steps)}")
        logger.info(f"   â€¢ Confidence: {state.confidence_score:.3f}")
        logger.info(f"   â€¢ Modalities: {', '.join(analysis_state.modalities_covered)}")

        return result

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    def _classify_question_intent(self, question: str) -> str:
        """åˆ†ç±»é—®é¢˜æ„å›¾"""
        question_lower = question.lower()

        if any(w in question_lower for w in ['compare', 'difference', 'versus', 'vs']):
            return 'comparison'
        elif any(w in question_lower for w in ['comprehensive', 'detailed', 'everything']):
            return 'comprehensive'
        elif any(w in question_lower for w in ['why', 'explain', 'how']):
            return 'explanatory'
        else:
            return 'simple_query'

    def _convert_candidate_to_reasoning(self,
                                        candidate: 'CandidateStep',
                                        step_number: int,
                                        analysis_state: 'AnalysisState') -> ReasoningStep:
        """
        å°†CandidateStepè½¬æ¢ä¸ºReasoningStep
        """
        # è§£æå‚æ•° (æ›¿æ¢å ä½ç¬¦)
        params = candidate.parameters.copy()

        # å¦‚æœå‚æ•°ä¸­æœ‰å¼•ç”¨discovered_entitiesçš„,æ›¿æ¢ä¹‹
        for key, value in params.items():
            if isinstance(value, str) and value.startswith('$'):
                # ä¾‹å¦‚: $regions -> analysis_state.discovered_entities['Region']
                entity_type = value[1:].title()  # $regions -> Regions -> Region
                if entity_type.endswith('s'):
                    entity_type = entity_type[:-1]

                if entity_type in analysis_state.discovered_entities:
                    params[key] = analysis_state.discovered_entities[entity_type][:10]

        return ReasoningStep(
            step_number=step_number,
            purpose=candidate.purpose,
            action='execute_cypher',
            rationale=candidate.rationale + f" (LLM score: {candidate.llm_score:.2f})",
            expected_result=candidate.expected_data,
            query_or_params={
                'query': candidate.cypher_template,
                'params': params
            },
            modality=candidate.step_type if candidate.step_type != 'spatial' else None,
            depends_on=[]
        )

    def _update_analysis_state(self,
                               analysis_state: 'AnalysisState',
                               step: ReasoningStep,
                               result: Dict,
                               candidate: 'CandidateStep'):
        """
        æ›´æ–°åˆ†æçŠ¶æ€
        """
        # è®°å½•æ‰§è¡Œçš„æ­¥éª¤
        analysis_state.executed_steps.append({
            'purpose': step.purpose,
            'modality': step.modality,
            'row_count': len(result.get('data', [])),
            'step_id': candidate.step_id
        })

        # æ›´æ–°modalityè¦†ç›–
        if step.modality and step.modality not in analysis_state.modalities_covered:
            analysis_state.modalities_covered.append(step.modality)

        # ğŸ†• æå–æ–°å‘ç°çš„å®ä½“
        data = result.get('data', [])
        if not data:
            return

        first_row = data[0]

        # æå–regions
        if 'region' in first_row or 'acronym' in first_row:
            regions = list(set([
                row.get('region') or row.get('acronym')
                for row in data
                if row.get('region') or row.get('acronym')
            ]))

            existing = analysis_state.discovered_entities.setdefault('Region', [])
            for r in regions:
                if r not in existing:
                    existing.append(r)

        # æå–clusters
        if 'cluster' in first_row or 'cluster_name' in first_row:
            clusters = list(set([
                row.get('cluster') or row.get('cluster_name')
                for row in data
                if row.get('cluster') or row.get('cluster_name')
            ]))

            existing = analysis_state.discovered_entities.setdefault('Cluster', [])
            for c in clusters:
                if c not in existing:
                    existing.append(c)

        # æå–subclasses
        if 'subclass' in first_row or 'subclass_name' in first_row:
            subclasses = list(set([
                row.get('subclass') or row.get('subclass_name')
                for row in data
                if row.get('subclass') or row.get('subclass_name')
            ]))

            existing = analysis_state.discovered_entities.setdefault('Subclass', [])
            for s in subclasses:
                if s not in existing:
                    existing.append(s)

        # ğŸ†• æå–projection targets
        if 'target' in first_row or 'target_region' in first_row:
            targets = list(set([
                row.get('target') or row.get('target_region')
                for row in data
                if row.get('target') or row.get('target_region')
            ]))

            existing = analysis_state.discovered_entities.setdefault('ProjectionTarget', [])
            for t in targets:
                if t not in existing:
                    existing.append(t)

            logger.info(f"   ğŸ“ Discovered {len(targets)} projection targets")

    def _determine_analysis_depth(self, question: str) -> AnalysisDepth:
        """æ ¹æ®é—®é¢˜ç¡®å®šåˆ†ææ·±åº¦"""

        question_lower = question.lower()

        # Deep: comprehensive, detailed, everything, full, complete
        if any(kw in question_lower for kw in ['comprehensive', 'detailed', 'everything', 'complete', 'full']):
            return AnalysisDepth.DEEP

        # Shallow: simple, basic, quick, overview
        if any(kw in question_lower for kw in ['simple', 'basic', 'quick', 'overview', 'briefly']):
            return AnalysisDepth.SHALLOW

        # Default: Medium
        return AnalysisDepth.MEDIUM

    # def _update_analysis_state(self,
    #                            state: AnalysisState,
    #                            step: ReasoningStep,
    #                            result: Dict):
    #     """æ›´æ–°åˆ†æçŠ¶æ€"""
    #
    #     # è®°å½•æ‰§è¡Œçš„æ­¥éª¤
    #     state.executed_steps.append({
    #         'purpose': step.purpose,
    #         'modality': step.modality,
    #         'row_count': len(result.get('data', []))
    #     })
    #
    #     # æ›´æ–°modalityè¦†ç›–
    #     if step.modality and step.modality not in state.modalities_covered:
    #         state.modalities_covered.append(step.modality)
    #
    #     # æå–æ–°å‘ç°çš„å®ä½“
    #     data = result.get('data', [])
    #     if data:
    #         # å¦‚æœæ˜¯regions
    #         if 'region' in data[0] or 'acronym' in data[0]:
    #             regions = [row.get('region') or row.get('acronym') for row in data]
    #             state.discovered_entities.setdefault('Region', []).extend(regions)
    #
    #         # å¦‚æœæ˜¯clusters
    #         if 'cluster' in data[0] or 'cluster_name' in data[0]:
    #             clusters = [row.get('cluster') or row.get('cluster_name') for row in data]
    #             state.discovered_entities.setdefault('Cluster', []).extend(clusters)
    #
    #         # å¦‚æœæ˜¯projection targets
    #         if 'target' in data[0]:
    #             targets = [row['target'] for row in data]
    #             state.discovered_entities.setdefault('ProjectionTarget', []).extend(targets)

    # ==================== Enhanced Planning Phase ====================

    def _enhanced_planning_phase(self, state: EnhancedAgentState) -> Dict[str, Any]:
        """
        å¢å¼ºçš„è§„åˆ’é˜¶æ®µ

        æ­¥éª¤:
        1. æ™ºèƒ½å®ä½“è¯†åˆ« (æ— hardcodedåˆ—è¡¨!)
        2. å®ä½“èšç±»
        3. åŠ¨æ€Schemaè·¯å¾„è§„åˆ’
        4. LLMç²¾åŒ–
        """
        try:
            # Step 1: å®ä½“è¯†åˆ«
            logger.info("  [1/4] Intelligent entity recognition...")
            entity_matches = self.entity_recognizer.recognize_entities(state.question)
            state.entity_matches = entity_matches

            logger.info(f"     Found {len(entity_matches)} entity matches")
            for match in entity_matches[:5]:
                logger.info(f"       â€¢ {match.text} ({match.entity_type}) [{match.confidence:.2f}]")

            # Step 2: å®ä½“èšç±»
            logger.info("  [2/4] Entity clustering...")
            entity_clusters = self.entity_clusterer.cluster_entities(
                entity_matches,
                state.question
            )
            state.entity_clusters = entity_clusters

            logger.info(f"     Created {len(entity_clusters)} entity clusters")
            for cluster in entity_clusters:
                logger.info(f"       â€¢ {cluster.cluster_type}: {cluster.primary_entity.text}")

            # Step 3: åŠ¨æ€Schemaè·¯å¾„è§„åˆ’
            logger.info("  [3/4] Dynamic schema path planning...")
            query_plans = self.path_planner.generate_plan(entity_clusters, state.question)

            logger.info(f"     Generated {len(query_plans)} query plans")

            # è®°å½•ä½¿ç”¨çš„schemaè·¯å¾„
            for plan in query_plans:
                if plan.schema_path.hops:
                    state.schema_paths_used.append({
                        'start': plan.schema_path.start_label,
                        'end': plan.schema_path.end_label,
                        'hops': len(plan.schema_path.hops),
                        'score': plan.schema_path.score
                    })

            # Step 4: LLMç²¾åŒ–
            logger.info("  [4/4] LLM plan refinement...")
            refined_steps = self._llm_refine_plans(query_plans, state)
            state.reasoning_plan = refined_steps

            # ä¿å­˜å®ä½“åˆ°state (å…¼å®¹åŸæœ‰æ ¼å¼)
            state.entities = [
                {
                    'text': m.text,
                    'type': m.entity_type,
                    'confidence': m.confidence
                }
                for m in entity_matches[:10]
            ]

            return {'success': True}

        except Exception as e:
            logger.error(f"Enhanced planning failed: {e}")
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}

    def _llm_refine_plans(self,
                          query_plans: List,
                          state: EnhancedAgentState) -> List[ReasoningStep]:
        """
        LLMç²¾åŒ–æŸ¥è¯¢è®¡åˆ’

        å°†åŠ¨æ€ç”Ÿæˆçš„QueryPlanè½¬æ¢ä¸ºReasoningStep,å¹¶è®©LLMè¡¥å……ç»†èŠ‚
        """
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        plans_dict = []
        for qp in query_plans:
            plans_dict.append({
                'step': qp.step_number,
                'purpose': qp.purpose,
                'action': qp.action,
                'query': qp.cypher_template,
                'parameters': qp.parameters,
                'modality': qp.modality,
                'depends_on': qp.depends_on,
                'schema_path_score': qp.schema_path.score if qp.schema_path else 0.0
            })

        prompt = f"""You are refining a reasoning plan for neuroscience knowledge graph analysis.

**Question:** {state.question}

**Recognized Entities:** {', '.join([e['text'] for e in state.entities])}

**Dynamically Generated Query Plans:**
{json.dumps(plans_dict, indent=2)}

Your task:
1. Review each query plan
2. Add detailed **expected_result** descriptions
3. Enhance **rationale** with domain knowledge
4. Verify Cypher query correctness
5. Add any missing steps if needed

Return a JSON object with key "steps" containing an array:
{{
  "steps": [
    {{
      "step_number": 1,
      "purpose": "...",
      "action": "execute_cypher",
      "rationale": "Detailed explanation",
      "expected_result": "Concrete prediction of what data will look like",
      "query_or_params": {{"query": "...", "params": {{}}}},
      "modality": "molecular/morphological/projection",
      "depends_on": []
    }},
    ...
  ]
}}

**Important:**
- Make rationale SPECIFIC and scientifically grounded
- Expected results should describe DATA PATTERNS (e.g., "10-20 clusters with neuron counts ranging 500-5000")
- Ensure query syntax is correct
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert neuroscientist and Neo4j query expert."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.2
            )

            result = json.loads(response.choices[0].message.content)

            # è½¬æ¢ä¸ºReasoningStep
            steps = []
            for step_dict in result.get('steps', []):
                query_or_params = step_dict.get('query_or_params', {})

                # å¤„ç†å‚æ•°æ›¿æ¢
                if isinstance(query_or_params, dict):
                    if 'query' not in query_or_params and 'query' in step_dict:
                        query_or_params = {'query': step_dict['query']}

                step = ReasoningStep(
                    step_number=step_dict.get('step_number', len(steps) + 1),
                    purpose=step_dict.get('purpose', ''),
                    action=step_dict.get('action', 'execute_cypher'),
                    rationale=step_dict.get('rationale', ''),
                    expected_result=step_dict.get('expected_result', ''),
                    query_or_params=query_or_params,
                    modality=step_dict.get('modality'),
                    depends_on=step_dict.get('depends_on', [])
                )
                steps.append(step)

            return steps

        except Exception as e:
            logger.error(f"LLM refinement failed: {e}")

            # Fallback: ç›´æ¥è½¬æ¢QueryPlan
            fallback_steps = []
            for qp in query_plans:
                step = ReasoningStep(
                    step_number=qp.step_number,
                    purpose=qp.purpose,
                    action=qp.action,
                    rationale="Automatically generated from schema path",
                    expected_result="Data matching query criteria",
                    query_or_params={'query': qp.cypher_template, 'params': qp.parameters},
                    modality=qp.modality,
                    depends_on=qp.depends_on
                )
                fallback_steps.append(step)

            return fallback_steps

    # ==================== Execution ====================

    def _execute_step(self, step: ReasoningStep, state: EnhancedAgentState) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        start_time = time.time()

        try:
            query = step.query_or_params.get('query', '')
            params = step.query_or_params.get('params', {})

            # å‚æ•°æ›¿æ¢ (å¤„ç†ä¾èµ–)
            if step.depends_on:
                params = self._resolve_parameters(step, state, params)

            # æ‰§è¡ŒæŸ¥è¯¢
            result = self._execute_cypher(query, params)

            step.actual_result = result
            step.execution_time = time.time() - start_time

            # ä¿å­˜ä¸­é—´æ•°æ®
            step_key = f"step_{step.step_number}"
            state.intermediate_data[step_key] = result.get('data', [])

            return result

        except Exception as e:
            logger.error(f"Step execution failed: {e}")
            return {'success': False, 'error': str(e)}

    def _resolve_parameters(self,
                            step: ReasoningStep,
                            state: EnhancedAgentState,
                            params: Dict) -> Dict:
        """è§£ææ­¥éª¤ä¾èµ–çš„å‚æ•°"""
        resolved = params.copy()

        # æŸ¥æ‰¾ä¾èµ–æ­¥éª¤çš„æ•°æ®
        for dep_num in step.depends_on:
            dep_key = f"step_{dep_num}"
            if dep_key in state.intermediate_data:
                dep_data = state.intermediate_data[dep_key]

                # æå–å¸¸ç”¨å­—æ®µ
                if dep_data:
                    # æå–region acronyms
                    regions = []
                    for row in dep_data:
                        if 'region' in row:
                            regions.append(row['region'])
                        elif 'acronym' in row:
                            regions.append(row['acronym'])

                    if regions:
                        resolved['enriched_regions'] = regions[:10]
                        resolved['target_regions'] = regions[:10]

        return resolved

    def _execute_cypher(self, query: str, params: Dict) -> Dict[str, Any]:
        """æ‰§è¡ŒCypheræŸ¥è¯¢"""
        import re

        # ç¡®ä¿æœ‰LIMIT
        if not re.search(r'\bLIMIT\b', query, re.IGNORECASE):
            query = f"{query}\nLIMIT 100"

        return self.db.run(query, params)

    # ==================== Intelligent Replanning ====================

    def _intelligent_replan(self, state: EnhancedAgentState, from_step: int) -> bool:
        """
        æ™ºèƒ½é‡è§„åˆ’

        ä½¿ç”¨:
        - ç»“æ„åŒ–åæ€çš„å»ºè®®
        - æ›¿ä»£å‡è®¾
        - Schemaä¸­çš„æ›¿ä»£è·¯å¾„
        """
        logger.info(f"ğŸ”„ Intelligent replanning from step {from_step}")
        state.replanning_count += 1

        # è·å–æœ€è¿‘çš„ç»“æ„åŒ–åæ€
        if state.structured_reflections:
            last_reflection = state.structured_reflections[-1]

            # ä½¿ç”¨åæ€ä¸­çš„å»ºè®®
            logger.info(f"   Using reflection recommendations:")
            for rec in last_reflection.next_step_recommendations:
                logger.info(f"     â€¢ {rec}")

            # å¦‚æœæœ‰æ›¿ä»£å‡è®¾,å°è¯•ä½¿ç”¨
            if last_reflection.alternative_hypotheses:
                logger.info(f"   Found {len(last_reflection.alternative_hypotheses)} alternative hypotheses")

        # é‡æ–°ç”Ÿæˆè®¡åˆ’ (ä½¿ç”¨ç°æœ‰å®ä½“)
        try:
            query_plans = self.path_planner.generate_plan(
                state.entity_clusters,
                state.question
            )

            # æ›¿æ¢å‰©ä½™æ­¥éª¤
            new_steps = self._llm_refine_plans(query_plans, state)

            # æ›´æ–°plan,ä¿ç•™å·²æ‰§è¡Œçš„
            state.reasoning_plan = state.reasoning_plan[:from_step - 1] + new_steps

            logger.info(f"   âœ… Replanned with {len(new_steps)} new steps")
            return True

        except Exception as e:
            logger.error(f"   âŒ Replanning failed: {e}")
            return False

    # ==================== Answer Synthesis ====================

    def _synthesize_answer(self, state: EnhancedAgentState) -> str:
        """åˆæˆæœ€ç»ˆç­”æ¡ˆ"""
        # å‡†å¤‡è¯æ®æ‘˜è¦
        evidence = []
        for step in state.executed_steps:
            if step.actual_result and step.actual_result.get('success'):
                data_count = len(step.actual_result.get('data', []))
                evidence.append(f"- Step {step.step_number}: {step.purpose} ({data_count} results)")

        evidence_text = "\n".join(evidence)

        # å‡†å¤‡å…³é”®å‘ç°
        key_data = {}
        for step in state.executed_steps:
            if step.actual_result and step.actual_result.get('success'):
                data = step.actual_result.get('data', [])
                if data:
                    key_data[f"step_{step.step_number}"] = data[:5]  # Top 5

        # å‡†å¤‡ç»“æ„åŒ–åæ€æ‘˜è¦
        reflection_summary = []
        for r in state.structured_reflections:
            reflection_summary.append(
                f"Step {r.step_number}: {r.validation_status.value} "
                f"(confidence: {r.confidence_score:.2f})"
            )

        prompt = f"""Synthesize a comprehensive answer based on the reasoning trace.

**Original Question:** {state.question}

**Entities Recognized:** {', '.join([e['text'] for e in state.entities[:5]])}

**Reasoning Steps Executed:**
{chr(10).join([f"{i + 1}. {s.purpose}" for i, s in enumerate(state.executed_steps)])}

**Evidence Collected:**
{evidence_text}

**Key Findings (sample data):**
{json.dumps(key_data, indent=2, default=str)[:2000]}

**Structured Reflections:**
{chr(10).join(reflection_summary)}

**Your Task:**
Write a comprehensive, scientifically rigorous answer that:
1. Directly answers the original question
2. Cites specific quantitative findings with numbers
3. Explains the multi-step reasoning process briefly
4. Integrates molecular, morphological, and projection findings if available
5. Acknowledges any limitations or uncertainties
6. Is written for a neuroscience research audience

Make it publication-quality but accessible. Use proper scientific terminology.
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system",
                     "content": "You are a neuroscience writer synthesizing research analysis results."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )

            answer = response.choices[0].message.content.strip()
            state.final_answer = answer

            # ä¼°ç®—ç½®ä¿¡åº¦
            state.confidence_score = self._estimate_confidence(state)

            return answer

        except Exception as e:
            logger.error(f"Synthesis failed: {e}")
            return f"Analysis completed with {len(state.executed_steps)} steps. " \
                   f"Found {len(state.entities)} entities and executed multi-modal analysis."

    # ==================== Utilities ====================

    def _step_to_dict(self, step: ReasoningStep) -> Dict:
        """è½¬æ¢æ­¥éª¤ä¸ºå­—å…¸"""
        return {
            'step_number': step.step_number,
            'purpose': step.purpose,
            'action': step.action,
            'rationale': step.rationale,
            'expected_result': step.expected_result,
            'actual_result_summary': {
                'success': step.actual_result.get('success') if step.actual_result else False,
                'row_count': len(step.actual_result.get('data', [])) if step.actual_result else 0
            },
            'reflection': step.reflection,
            'validation_passed': step.validation_passed,
            'execution_time': step.execution_time,
            'modality': step.modality
        }

    def _estimate_confidence(self, state: EnhancedAgentState) -> float:
        """ä¼°ç®—ç½®ä¿¡åº¦"""
        if not state.structured_reflections:
            return 0.5

        # ä½¿ç”¨ç»“æ„åŒ–åæ€çš„ç½®ä¿¡åº¦
        confidences = [r.confidence_score for r in state.structured_reflections]
        avg_confidence = sum(confidences) / len(confidences)

        # è°ƒæ•´å› ç´ 

        # Factor 1: æ­¥éª¤å®Œæˆç‡
        completion_rate = len(state.executed_steps) / len(state.reasoning_plan) \
            if state.reasoning_plan else 0

        # Factor 2: é‡è§„åˆ’æƒ©ç½š
        replan_penalty = 0.95 ** state.replanning_count

        # ç»¼åˆ
        final_confidence = avg_confidence * (0.7 + 0.3 * completion_rate) * replan_penalty

        return min(1.0, max(0.0, final_confidence))

    def _build_error_response(self, question: str, error: str, start_time: float) -> Dict:
        """æ„å»ºé”™è¯¯å“åº”"""
        return {
            'question': question,
            'answer': f"Analysis failed: {error}",
            'error': error,
            'execution_time': time.time() - start_time,
            'success': False,
            'entities_recognized': [],
            'reasoning_plan': [],
            'executed_steps': [],
            'reflections': [],
            'confidence_score': 0.0
        }

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.db.close()


# ==================== Test ====================

def test_v10_agent():
    """æµ‹è¯•V10 agent"""
    import os

    print("\n" + "=" * 80)
    print("AIPOM-CoT V10 PRODUCTION TEST")
    print("=" * 80)

    agent = AIPOMCoTV10(
        neo4j_uri=os.getenv("NEO4J_URI", "bolt://localhost:7687"),
        neo4j_user=os.getenv("NEO4J_USER", "neo4j"),
        neo4j_pwd=os.getenv("NEO4J_PASSWORD", "neuroxiv"),
        database=os.getenv("NEO4J_DATABASE", "neo4j"),
        schema_json_path="./schema_output/schema.json",
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        model="gpt-4o"
    )

    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "Tell me about Car3+ neurons",
        "Compare Pvalb and Sst interneurons in MOs",
        "What are the projection targets of the claustrum?"
    ]

    for q in test_questions:
        print(f"\n{'=' * 80}")
        print(f"Q: {q}")
        print('=' * 80)

        result = agent.answer(q, max_iterations=8)

        print(f"\nâœ… Results:")
        print(f"   Entities: {len(result['entities_recognized'])}")
        print(f"   Steps: {result['total_steps']}")
        print(f"   Confidence: {result['confidence_score']:.3f}")
        print(f"   Time: {result['execution_time']:.2f}s")
        print(f"\nğŸ’¡ Answer:\n{result['answer'][:300]}...\n")

    agent.close()


def test_car3_comprehensive():
    """æµ‹è¯•Car3çš„å®Œæ•´åˆ†æ"""

    agent = AIPOMCoTV10(
        neo4j_uri=os.getenv("NEO4J_URI", "bolt://localhost:7687"),
        neo4j_user=os.getenv("NEO4J_USER", "neo4j"),
        neo4j_pwd=os.getenv("NEO4J_PASSWORD", "neuroxiv"),
        database=os.getenv("NEO4J_DATABASE", "neo4j"),
        schema_json_path="./schema_output/schema.json",
        openai_api_key=os.getenv("OPENAI_API_KEY",''),
        model="gpt-4o"
    )

    # ğŸ¯ å…³é”®: ä½¿ç”¨"comprehensive"è§¦å‘æ·±åº¦åˆ†æ
    question = "Give me a comprehensive analysis of Car3+ neurons"

    result = agent.answer(question, max_iterations=12)

    print("\n" + "=" * 80)
    print("FIGURE 3 STORY ARC ANALYSIS")
    print("=" * 80)

    print(f"\nTarget Depth: {result['adaptive_planning']['target_depth']}")
    print(f"Steps Executed: {result['adaptive_planning']['final_depth']}")
    print(f"Modalities: {', '.join(result['adaptive_planning']['modalities_covered'])}")

    print("\n" + "-" * 80)
    print("STEP-BY-STEP NARRATIVE:")
    print("-" * 80)

    for i, step in enumerate(result['executed_steps'], 1):
        print(f"\n{i}. {step['purpose']}")
        print(f"   Modality: {step['modality']}")
        print(f"   Data: {step['actual_result_summary']['row_count']} rows")
        print(f"   Confidence: {step['reflection']}")

    print("\n" + "-" * 80)
    print("ENTITIES DISCOVERED:")
    print("-" * 80)
    for entity_type, count in result['adaptive_planning']['entities_discovered'].items():
        print(f"  â€¢ {entity_type}: {count}")

    print("\n" + "-" * 80)
    print("VALIDATION CHECKLIST:")
    print("-" * 80)

    modalities = result['adaptive_planning']['modalities_covered']
    entities = result['adaptive_planning']['entities_discovered']

    checks = {
        'Has molecular analysis': 'molecular' in modalities,
        'Has morphological analysis': 'morphological' in modalities,
        'Has projection analysis': 'projection' in modalities,
        'Found regions': 'Region' in entities and entities['Region'] > 0,
        'Found projection targets': 'ProjectionTarget' in entities and entities['ProjectionTarget'] > 0,
        'Analyzed target composition': any(
            'target' in s['purpose'].lower() and 'composition' in s['purpose'].lower() for s in
            result['executed_steps'])
    }

    for check, passed in checks.items():
        status = "âœ…" if passed else "âŒ"
        print(f"  {status} {check}")

    # è®¡ç®—å®Œæ•´æ€§åˆ†æ•°
    completeness = sum(checks.values()) / len(checks) * 100
    print(f"\nğŸ“Š Story Completeness: {completeness:.0f}%")

    if completeness >= 80:
        print("\nğŸ‰ âœ… FIGURE 3 COMPLETE STORY ARC ACHIEVED!")
    else:
        print(f"\nâš ï¸  Story incomplete - missing {100 - completeness:.0f}% of elements")

    print("\n" + "=" * 80)
    print("FINAL ANSWER:")
    print("=" * 80)
    print(result['answer'])

    agent.close()

    return result

if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    test_car3_comprehensive()