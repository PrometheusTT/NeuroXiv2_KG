"""
Baseline Methods for AIPOM-CoT Benchmark (v2.1 - GPT-5)
========================================================
åŒ…å«4ä¸ªbaselineæ–¹æ³•ï¼š
1. Direct GPT-5 - æœ€å¼ºLLM baseline
2. Template-KG - æ¨¡æ¿åŒ–KGæŸ¥è¯¢
3. RAG - æ£€ç´¢å¢žå¼ºç”Ÿæˆ (with GPT-5)
4. ReAct - æŽ¨ç†+è¡ŒåŠ¨ (with GPT-5)

Changes in v2.1:
- ä½¿ç”¨GPT-5æ›¿ä»£æ‰€æœ‰LLMè°ƒç”¨
- ç§»é™¤o1-previewï¼ˆä½¿ç”¨GPT-5ä½œä¸ºSOTA baselineï¼‰

Author: Claude & PrometheusTT
Date: 2025-01-15
Version: 2.1
"""

import time
import json
import logging
import re
from typing import Dict, Any, List, Optional
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


# ==================== Abstract Base Class ====================

class BaselineAgent(ABC):
    """BaselineæŠ½è±¡åŸºç±»"""

    def __init__(self, name: str):
        self.name = name

    @abstractmethod
    def answer(self, question: str, timeout: int = 120) -> Dict[str, Any]:
        """å›žç­”é—®é¢˜"""
        pass


# ==================== Baseline 1: Direct GPT-5 ====================

class DirectGPT5Baseline(BaselineAgent):
    """
    Direct GPT-5 Baseline (SOTA LLM)

    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨æœ€æ–°çš„GPT-5æ¨¡åž‹
    - æ— KGè®¿é—®
    - çº¯ç²¹ä¾èµ–é¢„è®­ç»ƒçŸ¥è¯†
    - å•æ¬¡æŽ¨ç†ï¼ˆfastï¼‰

    ä¼˜åŠ¿ï¼š
    - SOTAè¯­è¨€ç†è§£å’ŒæŽ¨ç†èƒ½åŠ›
    - é€Ÿåº¦å¿«
    - å¯¹å¸¸è¯†æ€§é—®é¢˜è¡¨çŽ°å¥½

    åŠ£åŠ¿ï¼š
    - æ— æ³•è®¿é—®æœ€æ–°/ä¸“æœ‰æ•°æ®
    - å¯èƒ½äº§ç”Ÿå¹»è§‰
    - æ— ç³»ç»Ÿåˆ†æžèƒ½åŠ›
    """

    def __init__(self, openai_client):
        super().__init__("Direct GPT-5")
        self.client = openai_client
        self.model = "gpt-5"

    def answer(self, question: str, timeout: int = 120) -> Dict[str, Any]:
        """ä½¿ç”¨GPT-5ç›´æŽ¥å›žç­”"""
        start_time = time.time()

        # ðŸ”§ é«˜è´¨é‡çš„system prompt
        system_prompt = """You are an expert neuroscientist with deep knowledge of:
- Brain anatomy and neuroanatomy (Allen Mouse Brain Atlas)
- Cell types and molecular markers (Pvalb, Sst, VIP, Car3, etc.)
- Neuronal morphology and electrophysiology
- Brain connectivity and neural circuits
- Mouse brain regions and their functions

Provide scientifically accurate, detailed answers based on your knowledge.
Include specific quantitative data when possible (neuron counts, connectivity strengths, etc.).
If you're uncertain about specific details, acknowledge it rather than speculate."""

        user_prompt = f"""Question about neuroscience:

{question}

Please provide a comprehensive, scientifically rigorous answer that includes:
1. Direct answer to the question
2. Relevant molecular markers or cell types (if applicable)
3. Brain regions involved (if applicable)
4. Quantitative data when available
5. Key scientific context

Answer:"""

        try:
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_completion_tokens=1500,
                timeout=timeout
            )

            answer = completion.choices[0].message.content
            execution_time = time.time() - start_time

            # æå–å®žä½“
            entities_recognized = self._extract_entities_heuristic(answer)

            return {
                'question': question,
                'answer': answer,
                'entities_recognized': entities_recognized,
                'executed_steps': [{
                    'purpose': 'Direct GPT-5 inference',
                    'modality': None,
                }],
                'schema_paths_used': [],
                'execution_time': execution_time,
                'total_steps': 1,
                'confidence_score': 0.75,  # é«˜ç½®ä¿¡ï¼ˆSOTA LLMï¼‰
                'success': True,
                'method': 'Direct GPT-5',
            }

        except Exception as e:
            logger.error(f"Direct GPT-5 failed: {e}")
            return self._error_response(question, str(e), time.time() - start_time)

    def _extract_entities_heuristic(self, answer: str) -> List[Dict]:
        """å¯å‘å¼æå–å®žä½“"""
        entities = []

        # æå–è„‘åŒºç¼©å†™ (2-5ä¸ªå¤§å†™å­—æ¯)
        regions = re.findall(r'\b[A-Z]{2,5}\b', answer)
        for r in set(regions):
            # æŽ’é™¤å¸¸è§éžè„‘åŒºè¯
            if r not in ['DNA', 'RNA', 'ATP', 'GABA', 'LLM', 'GPT', 'USA', 'PHD']:
                entities.append({
                    'text': r,
                    'type': 'Region',
                    'confidence': 0.7,
                })

        # æå–åŸºå› å (é¦–å­—æ¯å¤§å†™ + å°å†™å­—æ¯)
        genes = re.findall(r'\b[A-Z][a-z]{2,8}\+?\b', answer)
        for g in set(genes):
            # æŽ’é™¤å¸¸è§éžåŸºå› è¯
            if g not in ['The', 'This', 'That', 'There', 'These', 'Their', 'When', 'Where', 'Which']:
                entities.append({
                    'text': g.rstrip('+'),
                    'type': 'Gene',
                    'confidence': 0.6,
                })

        return entities[:15]

    def _error_response(self, question: str, error: str, elapsed: float) -> Dict:
        return {
            'question': question,
            'answer': f"Error: {error}",
            'entities_recognized': [],
            'executed_steps': [],
            'schema_paths_used': [],
            'execution_time': elapsed,
            'total_steps': 0,
            'confidence_score': 0.0,
            'success': False,
            'method': 'Direct GPT-5',
            'error': error,
        }


# ==================== Baseline 2: Template-KG ====================

class TemplateKGBaseline(BaselineAgent):
    """
    Template-based Knowledge Graph Query Baseline

    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨é¢„å®šä¹‰æŸ¥è¯¢æ¨¡æ¿
    - æœ‰KGè®¿é—®ï¼ˆå…¬å¹³å¯¹æ¯”ï¼‰
    - æ— è‡ªé€‚åº”èƒ½åŠ›
    - ä½¿ç”¨GPT-5åˆæˆç­”æ¡ˆ
    """

    def __init__(self, neo4j_exec, openai_client):
        super().__init__("Template-KG")
        self.db = neo4j_exec
        self.client = openai_client
        self.model = "gpt-5"  # ðŸ”§ ä½¿ç”¨GPT-5
        self.templates = self._build_templates()

    def _build_templates(self) -> Dict:
        """æž„å»ºæŸ¥è¯¢æ¨¡æ¿åº“"""
        return {
            # æ¨¡æ¿1ï¼šåŸºå›  â†’ ç»†èƒžç°‡
            'gene_to_clusters': """
                MATCH (c:Cluster)
                WHERE c.markers CONTAINS $gene
                RETURN c.name AS cluster, 
                       c.number_of_neurons AS neurons,
                       c.broad_region_distribution AS regions,
                       c.markers AS markers
                ORDER BY c.number_of_neurons DESC
                LIMIT 20
            """,

            # æ¨¡æ¿2ï¼šè„‘åŒº â†’ ç»†èƒžç°‡
            'region_to_clusters': """
                MATCH (r:Region)-[:HAS_CLUSTER]->(c:Cluster)
                WHERE r.acronym = $region
                RETURN r.name AS region_name, 
                       c.name AS cluster,
                       c.markers AS markers, 
                       c.number_of_neurons AS neurons
                ORDER BY c.number_of_neurons DESC
                LIMIT 30
            """,

            # æ¨¡æ¿3ï¼šè„‘åŒº â†’ æŠ•å°„
            'region_projections': """
                MATCH (r:Region)-[p:PROJECT_TO]->(t:Region)
                WHERE r.acronym = $region
                RETURN r.name AS source, 
                       t.acronym AS target, 
                       t.name AS target_name,
                       p.weight AS weight,
                       p.neuron_count AS neuron_count
                ORDER BY p.weight DESC
                LIMIT 20
            """,

            # æ¨¡æ¿4ï¼šè„‘åŒº â†’ å½¢æ€
            'region_morphology': """
                MATCH (n:Neuron)-[:LOCATE_AT]->(r:Region)
                WHERE r.acronym = $region
                RETURN r.name AS region,
                       count(n) AS neuron_count,
                       avg(n.axonal_length) AS avg_axon_length,
                       avg(n.dendritic_length) AS avg_dendrite_length,
                       avg(n.axonal_branches) AS avg_axon_branches,
                       avg(n.dendritic_branches) AS avg_dendrite_branches
            """,

            # æ¨¡æ¿5ï¼šåŸºå›  â†’ è„‘åŒºï¼ˆenrichmentï¼‰
            'gene_to_regions': """
                MATCH (r:Region)-[:HAS_CLUSTER]->(c:Cluster)
                WHERE c.markers CONTAINS $gene
                WITH r, count(c) AS cluster_count, sum(c.number_of_neurons) AS total_neurons
                RETURN r.acronym AS region,
                       r.name AS region_name,
                       cluster_count,
                       total_neurons
                ORDER BY total_neurons DESC
                LIMIT 15
            """,
        }

    def answer(self, question: str, timeout: int = 120) -> Dict[str, Any]:
        """ä½¿ç”¨æ¨¡æ¿å›žç­”é—®é¢˜"""
        start_time = time.time()

        try:
            # Step 1: åˆ†ç±»é—®é¢˜
            question_type = self._classify_question(question)
            logger.info(f"  Template-KG: Classified as '{question_type}'")

            # Step 2: æå–å‚æ•°
            params = self._extract_parameters(question)
            logger.info(f"  Template-KG: Extracted params: {params}")

            if not params:
                return self._fallback_answer(question, time.time() - start_time)

            # Step 3: æ‰§è¡Œæ¨¡æ¿
            results = []
            executed_steps = []

            if question_type == 'gene_profiling':
                results, executed_steps = self._execute_gene_profiling(params)

            elif question_type == 'region_analysis':
                results, executed_steps = self._execute_region_analysis(params)

            elif question_type == 'projection_query':
                results, executed_steps = self._execute_projection_query(params)

            else:
                results, executed_steps = self._execute_simple_lookup(params)

            # Step 4: åˆæˆç­”æ¡ˆï¼ˆä½¿ç”¨GPT-5ï¼‰
            if not results or not any(r.get('success') for r in results):
                return self._fallback_answer(question, time.time() - start_time)

            answer = self._synthesize_answer(question, results)

            execution_time = time.time() - start_time

            # æå–å®žä½“
            entities_recognized = []
            for key, value in params.items():
                if value:
                    entities_recognized.append({
                        'text': value,
                        'type': 'Gene' if key == 'gene' else 'Region',
                        'confidence': 1.0,
                    })

            return {
                'question': question,
                'answer': answer,
                'entities_recognized': entities_recognized,
                'executed_steps': executed_steps,
                'schema_paths_used': [s['template'] for s in executed_steps],
                'execution_time': execution_time,
                'total_steps': len(executed_steps),
                'confidence_score': 0.7,
                'success': True,
                'method': 'Template-KG',
            }

        except Exception as e:
            logger.error(f"Template-KG failed: {e}")
            import traceback
            traceback.print_exc()
            return self._error_response(question, str(e), time.time() - start_time)

    def _classify_question(self, question: str) -> str:
        """åˆ†ç±»é—®é¢˜ç±»åž‹"""
        q_lower = question.lower()

        if any(kw in q_lower for kw in ['tell me about', 'about', 'profile', 'characterize']):
            if any(kw in q_lower for kw in ['+', 'neuron', 'cell', 'interneuron']):
                return 'gene_profiling'
            else:
                return 'region_analysis'

        if any(kw in q_lower for kw in ['projection', 'project', 'target', 'connectivity']):
            return 'projection_query'

        return 'simple_lookup'

    def _extract_parameters(self, question: str) -> Dict:
        """æå–æŸ¥è¯¢å‚æ•°"""
        params = {}

        # æå–åŸºå› å
        genes = re.findall(r'\b([A-Z][a-z]{2,8})\+?', question)
        if genes:
            stopwords = {'What', 'Which', 'Where', 'Tell', 'Give', 'Show', 'Find', 'The', 'This', 'That'}
            for g in genes:
                if g not in stopwords:
                    params['gene'] = g
                    break

        # æå–è„‘åŒºç¼©å†™
        regions = re.findall(r'\b([A-Z]{2,5})\b', question)
        known_regions = {
            'MOp', 'MOs', 'SSp', 'SSs', 'VISp', 'VISal', 'VISam', 'VISl', 'VISpm',
            'AUDp', 'AUDpo', 'AUDv', 'ACA', 'PL', 'ILA', 'ORB',
            'RSP', 'CLA', 'HPF', 'HIP', 'TH', 'HY'
        }
        for r in regions:
            if r in known_regions:
                params['region'] = r
                break

        return params

    def _execute_gene_profiling(self, params: Dict) -> tuple:
        """æ‰§è¡ŒåŸºå› profilingæ¨¡æ¿åºåˆ—"""
        gene = params.get('gene')
        if not gene:
            return [], []

        results = []
        steps = []

        # Step 1: Gene -> Clusters
        result1 = self.db.run(self.templates['gene_to_clusters'], {'gene': gene})
        results.append(result1)
        steps.append({
            'purpose': f'Find clusters expressing {gene}',
            'template': 'gene_to_clusters',
            'modality': 'molecular',
            'success': result1.get('success', False),
        })

        # Step 2: Gene -> Regions
        result2 = self.db.run(self.templates['gene_to_regions'], {'gene': gene})
        results.append(result2)
        steps.append({
            'purpose': f'Find regions enriched for {gene}',
            'template': 'gene_to_regions',
            'modality': 'molecular',
            'success': result2.get('success', False),
        })

        # Step 3: å¦‚æžœæ‰¾åˆ°äº†primary regionï¼ŒæŸ¥è¯¢morphology
        if result2.get('success') and result2.get('data'):
            top_region = result2['data'][0].get('region')
            if top_region:
                result3 = self.db.run(self.templates['region_morphology'], {'region': top_region})
                results.append(result3)
                steps.append({
                    'purpose': f'Morphology of {top_region}',
                    'template': 'region_morphology',
                    'modality': 'morphological',
                    'success': result3.get('success', False),
                })

        return results, steps

    def _execute_region_analysis(self, params: Dict) -> tuple:
        """æ‰§è¡Œè„‘åŒºåˆ†æžæ¨¡æ¿åºåˆ—"""
        region = params.get('region')
        if not region:
            return [], []

        results = []
        steps = []

        # Step 1: Region -> Clusters
        result1 = self.db.run(self.templates['region_to_clusters'], {'region': region})
        results.append(result1)
        steps.append({
            'purpose': f'Cell types in {region}',
            'template': 'region_to_clusters',
            'modality': 'molecular',
            'success': result1.get('success', False),
        })

        # Step 2: Region -> Morphology
        result2 = self.db.run(self.templates['region_morphology'], {'region': region})
        results.append(result2)
        steps.append({
            'purpose': f'Morphology of {region}',
            'template': 'region_morphology',
            'modality': 'morphological',
            'success': result2.get('success', False),
        })

        # Step 3: Region -> Projections
        result3 = self.db.run(self.templates['region_projections'], {'region': region})
        results.append(result3)
        steps.append({
            'purpose': f'Projections from {region}',
            'template': 'region_projections',
            'modality': 'projection',
            'success': result3.get('success', False),
        })

        return results, steps

    def _execute_projection_query(self, params: Dict) -> tuple:
        """æ‰§è¡ŒæŠ•å°„æŸ¥è¯¢"""
        region = params.get('region')
        if not region:
            return [], []

        results = []
        steps = []

        result = self.db.run(self.templates['region_projections'], {'region': region})
        results.append(result)
        steps.append({
            'purpose': f'Projections from {region}',
            'template': 'region_projections',
            'modality': 'projection',
            'success': result.get('success', False),
        })

        return results, steps

    def _execute_simple_lookup(self, params: Dict) -> tuple:
        """æ‰§è¡Œç®€å•æŸ¥è¯¢"""
        results = []
        steps = []

        if 'gene' in params:
            result = self.db.run(self.templates['gene_to_clusters'], params)
            results.append(result)
            steps.append({
                'purpose': f'Lookup {params["gene"]}',
                'template': 'gene_to_clusters',
                'modality': 'molecular',
                'success': result.get('success', False),
            })

        elif 'region' in params:
            result = self.db.run(self.templates['region_to_clusters'], params)
            results.append(result)
            steps.append({
                'purpose': f'Lookup {params["region"]}',
                'template': 'region_to_clusters',
                'modality': 'molecular',
                'success': result.get('success', False),
            })

        return results, steps

    def _synthesize_answer(self, question: str, results: List[Dict]) -> str:
        """åˆæˆç­”æ¡ˆï¼ˆä½¿ç”¨GPT-5ï¼‰"""
        # æ”¶é›†æ‰€æœ‰æˆåŠŸçš„æ•°æ®
        all_data = []
        for result in results:
            if result.get('success') and result.get('data'):
                all_data.extend(result['data'][:10])

        if not all_data:
            return "No data found in knowledge graph."

        # æ ¼å¼åŒ–ä¸ºcontext
        context = "Data from Knowledge Graph:\n"
        for i, row in enumerate(all_data[:20], 1):
            context += f"\n{i}. "
            context += ", ".join(f"{k}: {v}" for k, v in list(row.items())[:5])

        # ðŸ”§ ä½¿ç”¨GPT-5åˆæˆ
        prompt = f"""Based on the following data from a neuroscience knowledge graph, provide a comprehensive answer.

Question: {question}

{context}

Provide a detailed, scientific answer using ONLY the data above. Include quantitative details and be precise."""

        try:
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a neuroscience expert analyzing knowledge graph data."},
                    {"role": "user", "content": prompt}
                ],
                max_completion_tokens=1000,
                timeout=30
            )

            return completion.choices[0].message.content

        except Exception as e:
            logger.error(f"GPT-5 synthesis failed: {e}")
            return f"Based on knowledge graph data: Found {len(all_data)} relevant entries. " + context[:500]

    def _fallback_answer(self, question: str, elapsed: float) -> Dict:
        """Fallback answer"""
        return {
            'question': question,
            'answer': "Unable to extract parameters or execute templates for this question.",
            'entities_recognized': [],
            'executed_steps': [],
            'schema_paths_used': [],
            'execution_time': elapsed,
            'total_steps': 0,
            'confidence_score': 0.0,
            'success': False,
            'method': 'Template-KG',
        }

    def _error_response(self, question: str, error: str, elapsed: float) -> Dict:
        return {
            'question': question,
            'answer': f"Error: {error}",
            'entities_recognized': [],
            'executed_steps': [],
            'schema_paths_used': [],
            'execution_time': elapsed,
            'total_steps': 0,
            'confidence_score': 0.0,
            'success': False,
            'method': 'Template-KG',
            'error': error,
        }


# ==================== Baseline 3: RAG (with GPT-5) ====================

class RAGBaseline(BaselineAgent):
    """RAG baseline (ä½¿ç”¨GPT-5)"""

    def __init__(self, neo4j_exec, openai_client):
        super().__init__("RAG")
        self.db = neo4j_exec
        self.client = openai_client
        self.model = "gpt-5"  # ðŸ”§ ä½¿ç”¨GPT-5

    def answer(self, question: str, timeout: int = 120) -> Dict[str, Any]:
        start_time = time.time()

        # æå–å…³é”®è¯
        keywords = self._extract_keywords(question)
        logger.info(f"  RAG keywords: {keywords}")

        # æ£€ç´¢æ–‡æ¡£
        docs = self._retrieve_documents(keywords, top_k=10)
        logger.info(f"  RAG retrieved {len(docs)} documents")

        # æž„å»ºprompt
        if docs:
            context = self._format_documents(docs)
        else:
            context = "No relevant documents found in the knowledge graph."

        # ç”Ÿæˆç­”æ¡ˆï¼ˆä½¿ç”¨GPT-5ï¼‰
        try:
            answer = self._generate_answer(question, context, timeout)
            execution_time = time.time() - start_time

            entities_recognized = self._extract_entities_from_docs(docs)

            return {
                'question': question,
                'answer': answer,
                'entities_recognized': entities_recognized,
                'executed_steps': [{
                    'purpose': f'Retrieved {len(docs)} documents from KG',
                    'modality': 'retrieval',
                }],
                'schema_paths_used': [],
                'execution_time': execution_time,
                'total_steps': 1,
                'confidence_score': 0.6,
                'success': True,
                'method': 'RAG',
            }

        except Exception as e:
            logger.error(f"RAG failed: {e}")
            return self._error_response(question, str(e), time.time() - start_time)

    def _extract_keywords(self, question: str) -> List[str]:
        """æå–å…³é”®è¯"""
        keywords = re.findall(r'\b[A-Z]{2,5}\b', question)
        keywords.extend(re.findall(r'\b[A-Z][a-z]{2,8}\+?\b', question))

        neuro_terms = [
            'neuron', 'neurons', 'cell', 'cells', 'cortex', 'region',
            'brain', 'axon', 'dendrite', 'projection', 'marker', 'cluster'
        ]
        q_lower = question.lower()
        keywords.extend([term for term in neuro_terms if term in q_lower])

        return list(set(keywords))[:5]

    def _retrieve_documents(self, keywords: List[str], top_k: int = 10) -> List[Dict]:
        """æ£€ç´¢æ–‡æ¡£"""
        docs = []

        for keyword in keywords:
            # Region
            query_region = """
            MATCH (r:Region)
            WHERE r.acronym CONTAINS $keyword OR r.name CONTAINS $keyword
            RETURN 'Region' AS type, r.acronym AS acronym, r.name AS name, 
                   r.number_of_transcriptomic_neurons AS neuron_count
            LIMIT 3
            """
            result = self.db.run(query_region, {'keyword': keyword})
            if result.get('success') and result.get('data'):
                docs.extend(result['data'])

            # Cluster
            query_cluster = """
            MATCH (c:Cluster)
            WHERE c.markers CONTAINS $keyword
            RETURN 'Cluster' AS type, c.name AS cluster_name, 
                   c.markers AS markers, c.number_of_neurons AS neurons
            ORDER BY c.number_of_neurons DESC
            LIMIT 3
            """
            result = self.db.run(query_cluster, {'keyword': keyword})
            if result.get('success') and result.get('data'):
                docs.extend(result['data'])

        # åŽ»é‡
        seen = set()
        unique_docs = []
        for doc in docs:
            key = json.dumps(doc, sort_keys=True)
            if key not in seen:
                seen.add(key)
                unique_docs.append(doc)

        return unique_docs[:top_k]

    def _format_documents(self, docs: List[Dict]) -> str:
        """æ ¼å¼åŒ–æ–‡æ¡£"""
        if not docs:
            return "No documents found."

        formatted = []
        for i, doc in enumerate(docs, 1):
            doc_type = doc.get('type', 'Unknown')

            if doc_type == 'Region':
                text = f"Region: {doc.get('name', 'N/A')} ({doc.get('acronym', 'N/A')})"
                if doc.get('neuron_count'):
                    text += f"\n  Neurons: {doc['neuron_count']:,}"

            elif doc_type == 'Cluster':
                text = f"Cluster: {doc.get('cluster_name', 'N/A')}"
                if doc.get('markers'):
                    text += f"\n  Markers: {doc['markers']}"
                if doc.get('neurons'):
                    text += f"\n  Neurons: {doc['neurons']:,}"

            else:
                text = json.dumps(doc, indent=2)

            formatted.append(f"Document {i}:\n{text}")

        return "\n\n".join(formatted)

    def _generate_answer(self, question: str, context: str, timeout: int) -> str:
        """ç”Ÿæˆç­”æ¡ˆï¼ˆä½¿ç”¨GPT-5ï¼‰"""

        system_prompt = """You are a neuroscience expert analyzing data from a knowledge graph.
Use ONLY the provided documents to answer the question.
Be precise and cite specific data from the documents.
If the documents don't contain sufficient information, acknowledge it."""

        user_prompt = f"""Based on the following documents from a neuroscience knowledge graph, answer the question.

Documents:
{context}

Question: {question}

Provide a detailed, scientific answer using ONLY information from the documents above.

Answer:"""

        completion = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            
            max_completion_tokens=1200,
            timeout=timeout
        )

        return completion.choices[0].message.content

    def _extract_entities_from_docs(self, docs: List[Dict]) -> List[Dict]:
        """ä»Žæ–‡æ¡£æå–å®žä½“"""
        entities = []

        for doc in docs:
            doc_type = doc.get('type')

            if doc_type == 'Region':
                entities.append({
                    'text': doc.get('acronym', ''),
                    'type': 'Region',
                    'confidence': 1.0,
                })

            elif doc_type == 'Cluster':
                markers = doc.get('markers', '')
                if markers:
                    for marker in markers.split(',')[:3]:
                        entities.append({
                            'text': marker.strip(),
                            'type': 'Gene',
                            'confidence': 0.9,
                        })

        return entities[:10]

    def _error_response(self, question: str, error: str, elapsed: float) -> Dict:
        return {
            'question': question,
            'answer': f"Error: {error}",
            'entities_recognized': [],
            'executed_steps': [],
            'schema_paths_used': [],
            'execution_time': elapsed,
            'total_steps': 0,
            'confidence_score': 0.0,
            'success': False,
            'method': 'RAG',
            'error': error,
        }


# ==================== Baseline 4: ReAct (with GPT-5) ====================

class ReActBaseline(BaselineAgent):
    """ReAct baseline (ä½¿ç”¨GPT-5ï¼Œå¢žåŠ max_iterations)"""

    def __init__(self, neo4j_exec, openai_client, max_iterations=5):
        super().__init__("ReAct")
        self.db = neo4j_exec
        self.client = openai_client
        self.model = "gpt-5"  # ðŸ”§ ä½¿ç”¨GPT-5
        self.max_iterations = max_iterations

    def answer(self, question: str, timeout: int = 120) -> Dict[str, Any]:
        start_time = time.time()

        history = []
        executed_steps = []
        entities_recognized = []

        system_prompt = """You are a neuroscience expert with access to a knowledge graph database.

You can execute Cypher queries to retrieve information.

Use the ReAct framework:
1. Thought: Reason about what information you need
2. Action: Either "query" to execute a Cypher query, or "answer" to provide final answer
3. Query: If action is "query", provide a Cypher query
4. Observation: System will provide query results
5. Repeat until you can answer

Respond in JSON format:
{
  "thought": "your reasoning about what to do next",
  "action": "query" or "answer",
  "query": "MATCH ... RETURN ..." (if action is "query", null otherwise),
  "final_answer": "your answer" (if action is "answer", null otherwise)
}

Keep queries simple and focused. Limit results to 20 rows."""

        try:
            for iteration in range(self.max_iterations):
                logger.info(f"  ReAct iteration {iteration + 1}/{self.max_iterations}")

                if history:
                    context = "\n\n".join(history)
                else:
                    context = "Start your reasoning."

                prompt = f"""Question: {question}

Previous steps:
{context}

What's your next step? Respond in JSON format."""

                # LLMæŽ¨ç†ï¼ˆä½¿ç”¨GPT-5ï¼‰
                completion = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": prompt}
                    ],
                    response_format={"type": "json_object"},
                    max_completion_tokens=800,
                    timeout=timeout // self.max_iterations
                )

                result = json.loads(completion.choices[0].message.content)

                thought = result.get('thought', '')
                action = result.get('action', '')

                history.append(f"Thought: {thought}")
                logger.info(f"    Thought: {thought[:80]}...")

                # å›žç­”
                if action == 'answer':
                    final_answer = result.get('final_answer', '')

                    execution_time = time.time() - start_time

                    return {
                        'question': question,
                        'answer': final_answer,
                        'entities_recognized': entities_recognized,
                        'executed_steps': executed_steps,
                        'schema_paths_used': [],
                        'execution_time': execution_time,
                        'total_steps': len(executed_steps),
                        'confidence_score': 0.7,
                        'success': True,
                        'method': 'ReAct',
                    }

                # æŸ¥è¯¢
                elif action == 'query':
                    query = result.get('query', '')

                    if not query:
                        logger.warning(f"    Empty query, skipping")
                        continue

                    history.append(f"Action: Execute query")
                    logger.info(f"    Executing query: {query[:80]}...")

                    db_result = self.db.run(query)

                    if db_result.get('success'):
                        data = db_result.get('data', [])[:20]
                        observation = f"Query returned {len(data)} results"

                        entities_recognized.extend(self._extract_entities_from_data(data))

                    else:
                        error = db_result.get('error', 'Unknown error')
                        observation = f"Query failed: {error}"
                        data = []

                    history.append(f"Observation: {observation}")
                    logger.info(f"    {observation}")

                    executed_steps.append({
                        'purpose': thought,
                        'query': query,
                        'result_count': len(data),
                        'success': db_result.get('success', False),
                        'modality': self._infer_modality(query),
                    })

            # è¾¾åˆ°æœ€å¤§è¿­ä»£
            logger.warning(f"  ReAct reached max iterations")

            final_answer = "Unable to complete analysis within iteration limit. "
            if executed_steps:
                final_answer += f"Executed {len(executed_steps)} queries but need more steps."
            else:
                final_answer += "Could not generate valid queries."

            return {
                'question': question,
                'answer': final_answer,
                'entities_recognized': entities_recognized,
                'executed_steps': executed_steps,
                'schema_paths_used': [],
                'execution_time': time.time() - start_time,
                'total_steps': len(executed_steps),
                'confidence_score': 0.4,
                'success': False,
                'method': 'ReAct',
            }

        except Exception as e:
            logger.error(f"ReAct failed: {e}")
            import traceback
            traceback.print_exc()
            return self._error_response(question, str(e), time.time() - start_time)

    def _infer_modality(self, query: str) -> str:
        """æŽ¨æ–­æŸ¥è¯¢çš„modality"""
        query_lower = query.lower()

        if 'project' in query_lower or 'target' in query_lower:
            return 'projection'
        elif 'morpholog' in query_lower or 'axon' in query_lower or 'dendrit' in query_lower:
            return 'morphological'
        elif 'cluster' in query_lower or 'marker' in query_lower:
            return 'molecular'
        else:
            return None

    def _extract_entities_from_data(self, data: List[Dict]) -> List[Dict]:
        """ä»Žæ•°æ®æå–å®žä½“"""
        entities = []

        for row in data[:5]:
            for key, value in row.items():
                if isinstance(value, str):
                    if len(value) >= 2 and len(value) <= 5 and value.isupper():
                        entities.append({
                            'text': value,
                            'type': 'Region',
                            'confidence': 0.8,
                        })
                    elif len(value) >= 3 and value[0].isupper():
                        entities.append({
                            'text': value,
                            'type': 'Gene',
                            'confidence': 0.6,
                        })

        seen = set()
        unique = []
        for e in entities:
            key = (e['text'], e['type'])
            if key not in seen:
                seen.add(key)
                unique.append(e)

        return unique[:10]

    def _error_response(self, question: str, error: str, elapsed: float) -> Dict:
        return {
            'question': question,
            'answer': f"Error: {error}",
            'entities_recognized': [],
            'executed_steps': [],
            'schema_paths_used': [],
            'execution_time': elapsed,
            'total_steps': 0,
            'confidence_score': 0.0,
            'success': False,
            'method': 'ReAct',
            'error': error,
        }


# ==================== Factory Function ====================

def create_baseline(baseline_type: str, **kwargs) -> BaselineAgent:
    """å·¥åŽ‚å‡½æ•°åˆ›å»ºbaseline"""

    if baseline_type == 'direct-gpt5':
        return DirectGPT5Baseline(
            openai_client=kwargs['openai_client']
        )

    elif baseline_type == 'template-kg':
        return TemplateKGBaseline(
            neo4j_exec=kwargs['neo4j_exec'],
            openai_client=kwargs['openai_client']
        )

    elif baseline_type == 'rag':
        return RAGBaseline(
            neo4j_exec=kwargs['neo4j_exec'],
            openai_client=kwargs['openai_client']
        )

    elif baseline_type == 'react':
        return ReActBaseline(
            neo4j_exec=kwargs['neo4j_exec'],
            openai_client=kwargs['openai_client'],
            max_iterations=kwargs.get('max_iterations', 5)
        )

    else:
        raise ValueError(f"Unknown baseline type: {baseline_type}")


# ==================== Test ====================

if __name__ == "__main__":
    print("âœ… Updated baselines.py v2.1 (GPT-5) loaded successfully!")
    print("\nAvailable baselines:")
    print("1. Direct GPT-5 - SOTA LLM (no KG)")
    print("2. Template-KG - Template-based KG query (with GPT-5)")
    print("3. RAG - Retrieval + Generation (with GPT-5)")
    print("4. ReAct - Reasoning + Acting (with GPT-5, max_iter=5)")