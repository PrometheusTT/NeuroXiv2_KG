"""
NeuroXiv-KG Agent
==================
æ— æ¯”å¼ºå¤§çš„è‡ªåŠ¨ç¥ç»æ•°æ®åˆ†æAgent

æ ¸å¿ƒèƒ½åŠ›ï¼š
1. LLMæ·±åº¦å‚ä¸ - çœŸæ­£çš„æ¨ç†è€Œéæ¨¡å¼åŒ¹é…
2. é«˜åº¦çµæ´» - åŠ¨æ€é€‚åº”ä¸åŒé—®é¢˜ç±»å‹
3. å¤šæ¨¡æ€æ•´åˆ - åˆ†å­/å½¢æ€/æŠ•å°„ä¸‰æ¨¡æ€åˆ†æ
4. é—­ç¯åˆ†æ - å®Œæ•´çš„circuitåˆ†æ
5. è‡ªæˆ‘åæ€ - æ™ºèƒ½å†³ç­–å’Œçº é”™

ä½¿ç”¨æ–¹å¼ï¼š
    agent = NeuroXivAgent.create(
        neo4j_uri="bolt://localhost:7687",
        neo4j_user="neo4j",
        neo4j_password="password",
        openai_api_key="sk-..."
    )

    result = agent.answer("Tell me about Car3+ neurons")
    print(result['answer'])

Author: Lijun
Date: 2025-01
"""

import os
import json
import logging
from typing import Dict, Any, Optional, List

from core_structures import (
    AgentConfig, SessionMemory, AnalysisState,
    Modality, AnalysisDepth, QuestionIntent
)

from llm_intelligence import LLMClient, OpenAIClient

from tpar_engine import TPAREngine

from adaptive_planner import SchemaGraph

logger = logging.getLogger(__name__)


# ==================== Database Executor ====================

class Neo4jExecutor:
    """
    Neo4jæ•°æ®åº“æ‰§è¡Œå™¨

    ç‰¹æ€§ï¼š
    - è‡ªåŠ¨LIMIT
    - é‡è¯•æœºåˆ¶
    - è¶…æ—¶æ§åˆ¶
    """

    def __init__(self,
                 uri: str,
                 user: str,
                 password: str,
                 database: str = "neo4j",
                 timeout: int = 30):

        from neo4j import GraphDatabase

        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        self.database = database
        self.timeout = timeout

    def run(self, query: str, params: Dict = None) -> Dict:
        """æ‰§è¡ŒæŸ¥è¯¢"""
        import re
        import time

        params = params or {}

        # ç¡®ä¿LIMIT
        if not re.search(r'\bLIMIT\b', query, re.IGNORECASE):
            query = f"{query}\nLIMIT 100"

        try:
            start = time.time()

            with self.driver.session(database=self.database) as session:
                result = session.run(query, params, timeout=self.timeout)
                data = [dict(record) for record in result]

            elapsed = time.time() - start

            return {
                'success': True,
                'data': data,
                'rows': len(data),
                'time': elapsed,
                'query': query
            }

        except Exception as e:
            logger.error(f"Query failed: {e}")
            return {
                'success': False,
                'data': [],
                'error': str(e),
                'query': query
            }

    def close(self):
        """å…³é—­è¿æ¥"""
        try:
            self.driver.close()
        except:
            pass


class MockExecutor:
    """æ¨¡æ‹Ÿæ‰§è¡Œå™¨ - ç”¨äºæµ‹è¯•"""

    def __init__(self):
        self._mock_data = self._load_mock_data()

    def _load_mock_data(self) -> Dict:
        """åŠ è½½æ¨¡æ‹Ÿæ•°æ®"""
        return {
            'regions': [
                {'acronym': 'MOp', 'name': 'Primary motor area'},
                {'acronym': 'MOs', 'name': 'Secondary motor area'},
                {'acronym': 'SSp', 'name': 'Primary somatosensory area'},
                {'acronym': 'VISp', 'name': 'Primary visual area'},
            ],
            'clusters': [
                {'name': 'L5 IT CTX', 'markers': 'Car3,Satb2', 'number_of_neurons': 12345},
                {'name': 'L6 CT CTX', 'markers': 'Car3,Fezf2', 'number_of_neurons': 9876},
                {'name': 'L4 IT CTX', 'markers': 'Car3,Rorb', 'number_of_neurons': 5432},
            ],
            'subclasses': [
                {'name': 'L5 IT', 'markers': 'Car3,Slc17a7', 'description': 'Layer 5 intratelencephalic'},
                {'name': 'L6 CT', 'markers': 'Car3,Fezf2', 'description': 'Layer 6 corticothalamic'},
            ],
            'gene_abbrevs': {
                'VIP': 'vasoactive intestinal peptide',
                'SST': 'somatostatin',
                'Pvalb': 'parvalbumin',
                'Car3': 'carbonic anhydrase 3',
                'Lamp5': 'lysosomal associated membrane protein 5',
            },
            'region_abbrevs': {
                'MOp': 'Primary motor area',
                'MOs': 'Secondary motor area',
                'SSp': 'Primary somatosensory area',
                'VISp': 'Primary visual area',
                'HIP': 'Hippocampus',
                'TH': 'Thalamus',
            }
        }

    def run(self, query: str, params: Dict = None) -> Dict:
        """æ¨¡æ‹Ÿæ‰§è¡ŒæŸ¥è¯¢"""
        params = params or {}
        query_lower = query.lower()

        # è§£ææŸ¥è¯¢ç±»å‹
        if 'subclass' in query_lower:
            if 'markers contains' in query_lower:
                gene = params.get('gene', '')
                data = [s for s in self._mock_data['subclasses']
                       if gene.lower() in s['markers'].lower()]
            else:
                data = self._mock_data['subclasses']

        elif 'cluster' in query_lower:
            if 'markers contains' in query_lower:
                gene = params.get('gene', '')
                data = [c for c in self._mock_data['clusters']
                       if gene.lower() in c['markers'].lower()]
            else:
                data = self._mock_data['clusters']

        elif 'region' in query_lower:
            if 'acronym' in query_lower and params.get('region'):
                region = params.get('region', '')
                data = [r for r in self._mock_data['regions']
                       if r['acronym'] == region]
            elif 'has_cluster' in query_lower:
                gene = params.get('gene', '')
                # æ¨¡æ‹Ÿregion enrichment
                data = [
                    {'region': 'MOp', 'region_name': 'Primary motor area',
                     'cluster_count': 15, 'total_neurons': 45000},
                    {'region': 'MOs', 'region_name': 'Secondary motor area',
                     'cluster_count': 12, 'total_neurons': 32000},
                    {'region': 'SSp', 'region_name': 'Primary somatosensory area',
                     'cluster_count': 18, 'total_neurons': 52000},
                ]
            else:
                data = self._mock_data['regions']

        elif 'neuron' in query_lower and 'locate_at' in query_lower:
            # å½¢æ€å­¦æŸ¥è¯¢
            data = [{
                'region': params.get('region', 'MOp'),
                'neuron_count': 1234,
                'avg_axon_length': 4567.89,
                'avg_dendrite_length': 1234.56,
                'avg_axon_branches': 45.6,
                'avg_dendrite_branches': 23.4,
            }]

        elif 'project_to' in query_lower:
            # æŠ•å°„æŸ¥è¯¢
            data = [
                {'source': 'MOp', 'target': 'TH', 'target_name': 'Thalamus',
                 'projection_weight': 0.85, 'neuron_count': 234},
                {'source': 'MOp', 'target': 'CP', 'target_name': 'Caudoputamen',
                 'projection_weight': 0.72, 'neuron_count': 189},
                {'source': 'MOp', 'target': 'SC', 'target_name': 'Superior colliculus',
                 'projection_weight': 0.56, 'neuron_count': 145},
            ]

        else:
            data = []

        return {
            'success': True,
            'data': data,
            'rows': len(data),
            'query': query
        }

    def close(self):
        pass


# ==================== Mock LLM Client ====================

class MockLLMClient(LLMClient):
    """
    æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯ - ç”¨äºæµ‹è¯•

    æä¾›æ™ºèƒ½çš„æ¨¡æ‹Ÿå“åº”
    """

    def __init__(self):
        self.call_count = 0

        # çŸ¥è¯†åº“
        self.knowledge = {
            'VIP': 'vasoactive intestinal peptide',
            'SST': 'somatostatin',
            'Pvalb': 'parvalbumin',
            'Car3': 'carbonic anhydrase 3',
            'Lamp5': 'lysosomal associated membrane protein 5',
            'MOp': 'Primary motor area',
            'MOs': 'Secondary motor area',
            'SSp': 'Primary somatosensory area',
            'VISp': 'Primary visual area',
        }

    def chat(self,
             messages: List[Dict],
             temperature: float = 0.2,
             max_tokens: int = 2000,
             json_mode: bool = False) -> str:

        self.call_count += 1

        # è·å–ç”¨æˆ·æ¶ˆæ¯
        user_msg = ""
        for msg in messages:
            if msg['role'] == 'user':
                user_msg = msg['content']
                break

        user_lower = user_msg.lower()

        # æ„å›¾åˆ†ç±»
        if 'analyze this neuroscience question' in user_lower:
            return self._mock_intent_response(user_msg)

        # å®ä½“æå–
        elif 'extract entities' in user_lower:
            return self._mock_entity_response(user_msg)

        # æ­¥éª¤æ’åº
        elif 'rank' in user_lower and 'steps' in user_lower:
            return self._mock_ranking_response(user_msg)

        # åæ€
        elif 'reflect' in user_lower:
            return self._mock_reflection_response(user_msg)

        # ç»¼åˆç­”æ¡ˆ
        elif 'synthesize' in user_lower:
            return self._mock_synthesis_response(user_msg)

        else:
            return "I understand the request."

    def _mock_intent_response(self, msg: str) -> str:
        """æ¨¡æ‹Ÿæ„å›¾åˆ†ç±»å“åº”"""
        msg_lower = msg.lower()

        # åˆ¤æ–­æ„å›¾
        if any(w in msg_lower for w in ['stand for', 'full name', 'abbreviation', 'what is']):
            intent = 'definition'
            depth = 'shallow'
            planner = 'adaptive'
        elif any(w in msg_lower for w in ['compare', 'versus', 'vs']):
            intent = 'comparison'
            depth = 'medium'
            planner = 'comparative'
        elif any(w in msg_lower for w in ['tell me about', 'comprehensive', 'analyze', 'profile']):
            intent = 'profiling'
            depth = 'deep'
            planner = 'focus_driven'
        elif any(w in msg_lower for w in ['which', 'top', 'highest', 'screen']):
            intent = 'screening'
            depth = 'medium'
            planner = 'comparative'
        else:
            intent = 'profiling'
            depth = 'medium'
            planner = 'adaptive'

        return json.dumps({
            'intent': intent,
            'intent_confidence': 0.9,
            'intent_reasoning': f'Detected {intent} intent',
            'recommended_depth': depth,
            'depth_reasoning': f'{depth} depth appropriate',
            'recommended_planner': planner,
            'planner_reasoning': f'{planner} is optimal',
            'expected_modalities': ['molecular', 'morphological', 'projection'],
            'modality_reasoning': 'Multi-modal analysis needed',
            'expected_entity_types': ['GeneMarker', 'Region'],
            'key_concepts': ['gene expression', 'cell types'],
            'sub_questions': ['What cell types express this gene?', 'Where are they located?'],
            'analysis_goals': ['Identify cell types', 'Map spatial distribution']
        })

    def _mock_entity_response(self, msg: str) -> str:
        """æ¨¡æ‹Ÿå®ä½“æå–å“åº”"""
        entities = []

        for gene, full_name in self.knowledge.items():
            if gene.lower() in msg.lower():
                if gene in ['VIP', 'SST', 'Pvalb', 'Car3', 'Lamp5']:
                    entities.append({
                        'text': gene,
                        'type': 'GeneMarker',
                        'confidence': 0.95
                    })
                else:
                    entities.append({
                        'text': gene,
                        'type': 'Region',
                        'confidence': 0.95
                    })

        return json.dumps({'entities': entities})

    def _mock_ranking_response(self, msg: str) -> str:
        """æ¨¡æ‹Ÿæ­¥éª¤æ’åºå“åº”"""
        # ç®€å•è¿”å›æŒ‰é¡ºåºæ’åº
        return json.dumps({
            'ranked_steps': [
                {'index': 0, 'score': 0.95, 'reasoning': 'High priority step'},
                {'index': 1, 'score': 0.85, 'reasoning': 'Secondary step'},
            ]
        })

    def _mock_reflection_response(self, msg: str) -> str:
        """æ¨¡æ‹Ÿåæ€å“åº”"""
        return json.dumps({
            'validation_status': 'passed',
            'validation_reasoning': 'Results match expectations',
            'key_findings': ['Found relevant data', 'Cell types identified'],
            'surprising_results': [],
            'uncertainty_level': 0.2,
            'uncertainty_sources': ['Limited sample size'],
            'decision': 'continue',
            'decision_reasoning': 'Analysis progressing well',
            'next_step_suggestions': ['Proceed with morphology analysis'],
            'alternative_approaches': [],
            'confidence_score': 0.85,
            'confidence_factors': {'data_quality': 0.9, 'expectation_match': 0.8},
            'summary': 'Step completed successfully with meaningful results.'
        })

    def _mock_synthesis_response(self, msg: str) -> str:
        """æ¨¡æ‹Ÿç»¼åˆç­”æ¡ˆ"""
        # ä»æ¶ˆæ¯ä¸­æå–é—®é¢˜
        question_match = msg.split('**Original Question:**')
        if len(question_match) > 1:
            question = question_match[1].split('\n')[0].strip()
        else:
            question = "the query"

        return f"""## Analysis Results

Based on the comprehensive multi-modal analysis, here are the key findings:

### Main Finding
The analysis successfully identified relevant cell populations and their characteristics across molecular, morphological, and projection modalities.

### Supporting Evidence
1. **Molecular**: Multiple cell clusters were identified expressing the target markers
2. **Morphological**: Neurons show characteristic axonal and dendritic patterns
3. **Projection**: Clear connectivity patterns to subcortical targets were mapped

### Multi-Modal Integration
The molecular identity correlates with distinct morphological features and projection patterns, suggesting functional specialization.

### Limitations
- Analysis based on available data in the knowledge graph
- Some regions may have limited morphological data

*Analysis completed with high confidence.*"""


# ==================== Main Agent Class ====================

class NeuroXivAgent:
    """
    NeuroXiv-KG Agent - æ— æ¯”å¼ºå¤§çš„è‡ªåŠ¨ç¥ç»æ•°æ®åˆ†æAgent

    æ ¸å¿ƒèƒ½åŠ›ï¼š
    1. LLMæ·±åº¦å‚ä¸æ¯ä¸ªå†³ç­–é˜¶æ®µ
    2. åŠ¨æ€è‡ªé€‚åº”çš„åˆ†æç­–ç•¥
    3. ä¸‰æ¨¡æ€æ•´åˆåˆ†æ
    4. å®Œæ•´çš„TPARå¾ªç¯
    5. æ™ºèƒ½é—­ç¯åˆ†æ
    """

    def __init__(self,
                 db_executor,
                 llm_client: LLMClient,
                 schema: SchemaGraph = None,
                 config: AgentConfig = None):
        """
        åˆå§‹åŒ–Agent

        Args:
            db_executor: æ•°æ®åº“æ‰§è¡Œå™¨
            llm_client: LLMå®¢æˆ·ç«¯
            schema: Schemaå›¾
            config: é…ç½®
        """
        self.db = db_executor
        self.llm = llm_client
        self.schema = schema or SchemaGraph()
        self.config = config or AgentConfig()

        # åˆå§‹åŒ–TPARå¼•æ“
        self.tpar_engine = TPAREngine(
            db_executor=db_executor,
            llm_client=llm_client,
            schema=schema,
            config=config
        )

        # ä¼šè¯è®°å¿†
        self.session_memory = SessionMemory()

        logger.info("ğŸš€ NeuroXiv-KG Agent initialized")
        logger.info(f"   â€¢ LLM: {type(llm_client).__name__}")
        logger.info(f"   â€¢ DB: {type(db_executor).__name__}")

    @classmethod
    def create(cls,
               neo4j_uri: str = None,
               neo4j_user: str = None,
               neo4j_password: str = None,
               neo4j_database: str = "neo4j",
               openai_api_key: str = None,
               model: str = "gpt-4o",
               schema_path: str = None,
               use_mock: bool = False) -> 'NeuroXivAgent':
        """
        å·¥å‚æ–¹æ³•ï¼šåˆ›å»ºAgentå®ä¾‹

        Args:
            neo4j_uri: Neo4j URI
            neo4j_user: Neo4jç”¨æˆ·å
            neo4j_password: Neo4jå¯†ç 
            neo4j_database: æ•°æ®åº“å
            openai_api_key: OpenAI API Key
            model: LLMæ¨¡å‹
            schema_path: Schema JSONè·¯å¾„
            use_mock: æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼

        Returns:
            NeuroXivAgentå®ä¾‹
        """
        # æ•°æ®åº“
        if use_mock:
            db_executor = MockExecutor()
            llm_client = MockLLMClient()
        else:
            # Neo4j
            uri = neo4j_uri or os.getenv("NEO4J_URI", "bolt://localhost:7687")
            user = neo4j_user or os.getenv("NEO4J_USER", "neo4j")
            password = neo4j_password or os.getenv("NEO4J_PASSWORD", "password")

            db_executor = Neo4jExecutor(uri, user, password, neo4j_database)

            # LLM
            api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
            if api_key:
                from openai import OpenAI
                client = OpenAI(api_key=api_key)
                llm_client = OpenAIClient(client, model)
            else:
                logger.warning("No OpenAI API key, using mock LLM")
                llm_client = MockLLMClient()

        # Schema
        schema = SchemaGraph()
        if schema_path and os.path.exists(schema_path):
            with open(schema_path) as f:
                schema_data = json.load(f)
            schema = SchemaGraph(schema_data)

        # Config
        config = AgentConfig(
            neo4j_uri=neo4j_uri or "",
            neo4j_user=neo4j_user or "",
            neo4j_password=neo4j_password or "",
            neo4j_database=neo4j_database,
            llm_model=model,
        )

        return cls(db_executor, llm_client, schema, config)

    def answer(self,
               question: str,
               max_iterations: int = None) -> Dict[str, Any]:
        """
        å›ç­”é—®é¢˜ - ä¸»å…¥å£

        Args:
            question: ç”¨æˆ·é—®é¢˜
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°

        Returns:
            åŒ…å«ç­”æ¡ˆå’Œåˆ†æè¯¦æƒ…çš„å­—å…¸
        """
        return self.tpar_engine.answer(question, max_iterations)

    def get_session_summary(self) -> Dict:
        """è·å–ä¼šè¯æ‘˜è¦"""
        return {
            'session_id': self.session_memory.session_id,
            'qa_count': len(self.session_memory.qa_history),
            'known_entities': {
                k: len(v) for k, v in self.session_memory.known_entities.items()
            }
        }

    def clear_session(self):
        """æ¸…é™¤ä¼šè¯"""
        self.session_memory = SessionMemory()
        self.tpar_engine.session_memory = SessionMemory()
        logger.info("Session cleared")

    def close(self):
        """å…³é—­è¿æ¥"""
        self.db.close()
        logger.info("Connections closed")


# ==================== Quick Test ====================

def quick_test():
    """å¿«é€Ÿæµ‹è¯•"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    print("\n" + "=" * 70)
    print("ğŸ§ª NeuroXiv-KG Agent Quick Test")
    print("=" * 70)

    # åˆ›å»ºæ¨¡æ‹ŸAgent
    agent = NeuroXivAgent.create(use_mock=True)

    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "What does VIP stand for?",
        "Tell me about Car3+ neurons",
        # "Compare MOp and MOs regions",
    ]

    for question in test_questions:
        print(f"\n{'=' * 60}")
        print(f"Q: {question}")
        print('=' * 60)

        result = agent.answer(question, max_iterations=5)

        print(f"\nâœ… Results:")
        print(f"   Steps: {result.get('total_steps', 0)}")
        print(f"   Confidence: {result.get('confidence_score', 0):.3f}")
        print(f"   Time: {result.get('execution_time', 0):.2f}s")

        if 'analysis_info' in result:
            info = result['analysis_info']
            print(f"   Intent: {info.get('intent', 'unknown')}")
            print(f"   Depth: {info.get('target_depth', 'unknown')}")
            print(f"   Modalities: {info.get('modalities_covered', [])}")

        print(f"\nğŸ’¡ Answer:\n{result.get('answer', 'No answer')[:500]}...")

    agent.close()
    print("\nâœ… Quick test complete!")


# ==================== Export ====================

__all__ = [
    'NeuroXivAgent',
    'Neo4jExecutor',
    'MockExecutor',
    'MockLLMClient',
    'quick_test',
]


if __name__ == "__main__":
    quick_test()